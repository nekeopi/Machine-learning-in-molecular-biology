{"cells":[{"cell_type":"markdown","metadata":{"id":"tHyTPLyFH_xN"},"source":["Purpose: In this assignment, you will implement and utilize Hidden Markov Models (HMMs) to\n","classify sequences into exons and introns based on their codon structure. You will achieve this by\n","training two HMMs: one on exon sequences and another on intron sequences. Using these\n","models, classify sequences by calculating the log likelihood of each sequence under both models.\n","\n","Programming\n","0. Spend 1 hour reading the documentation of hmmlearn (https://hmmlearn.readthedocs.io/).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2099,"status":"ok","timestamp":1736535597442,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"},"user_tz":-60},"id":"eBKM84tMzqm8","outputId":"0e1985f1-b6df-4866-b560-f45639e7ac99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12695,"status":"ok","timestamp":1736535595350,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"},"user_tz":-60},"id":"JwRbIKRzzo1-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26a31f23-25c8-4a65-fdf5-8889a2075f06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hmmlearn\n","  Downloading hmmlearn-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.26.4)\n","Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.6.0)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n","Downloading hmmlearn-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: hmmlearn\n","Successfully installed hmmlearn-0.3.3\n","Collecting biopython\n","  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n","Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopython\n","Successfully installed biopython-1.84\n"]}],"source":["!pip install hmmlearn\n","!pip install biopython\n","import numpy as np\n","import random\n","from Bio import SeqIO\n","from hmmlearn import hmm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"0qvrOQ1OxG00"},"source":["# Data Preparation\n","\n","1.1 Divide the provided sequences (exon.fa and intron.fa) into three groups:\n","• Training set (70%): Use this for estimating model parameters (priors, emissions, and\n","transitions).\n","• Validation set (20%): Use this for validating your classifier. We still need this set even\n","though we do not have hyper-parameters to tune; the design itself is a hyperparameter.\n","• Test set (10%): Use this for evaluating the performance of the classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TLM2hwaH5tr"},"outputs":[],"source":["random.seed(42)\n","np.random.seed(42)\n","\n","def read_fasta(filename): # extract sequences, change T with U\n","    sequences = []\n","    for record in SeqIO.parse(filename, \"fasta\"):\n","        seq_rna = str(record.seq).upper().replace('T', 'U')\n","        sequences.append((record.id, seq_rna))\n","    return sequences\n","\n","def split_data(sequences): # split the dataset into train, val. test\n","    random.shuffle(sequences)\n","    length = len(sequences)\n","    train_end = int(0.7 * length)\n","    val_end   = int(0.9 * length)\n","\n","    train_set = sequences[:train_end]\n","    val_set   = sequences[train_end:val_end]\n","    test_set  = sequences[val_end:]\n","    return train_set, val_set, test_set\n","\n","exons = read_fasta(\"/content/drive/MyDrive/mlinmb/6/exon.fa\")\n","introns = read_fasta(\"/content/drive/MyDrive/mlinmb/6/intron.fa\")\n","\n","train_exons, val_exons, test_exons = split_data(exons)\n","train_introns, val_introns, test_introns = split_data(introns)\n"]},{"cell_type":"markdown","source":["1.2 Use overlapping k-mers (k=3) to represent the sequences. For example, the\n","sequence ATGCGT would generate the overlapping k-mers: ATG, TGC, and GCG.\n"],"metadata":{"id":"sovvMeY773Y6"}},{"cell_type":"code","source":["def get_kmers(sequence, k=3): # getting overlapping kmers from sequences\n","    kmers = []\n","    for i in range(len(sequence) - k + 1):\n","        kmers.append(sequence[i : i + k])\n","    return kmers\n","\n","def prepare_kmers_list(seq_tuples, k=3): # generating list with sequence id and all kmers it contains\n","    output = []\n","    for (seq_id, seq_str) in seq_tuples:\n","        kmers = get_kmers(seq_str, k)\n","        output.append((seq_id, kmers))\n","    return output\n","\n","train_exons_kmers   = prepare_kmers_list(train_exons)\n","val_exons_kmers     = prepare_kmers_list(val_exons)\n","test_exons_kmers    = prepare_kmers_list(test_exons)\n","train_introns_kmers = prepare_kmers_list(train_introns)\n","val_introns_kmers   = prepare_kmers_list(val_introns)\n","test_introns_kmers  = prepare_kmers_list(test_introns)"],"metadata":{"id":"13-2iP_z48Sz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# Define the Hidden Markov Model (HMM)\n","\n","2.1 States (Hidden States): Each hidden state represents one of the 20 standard amino acids.\n","Additionally, include an extra state to handle k-mers that do not correspond to any amino acid,\n","resulting in a total of 21 states.\n","\n","2.2 Observations: Observations are the codons (trimers), which correspond to amino acids.\n","Multiple codons are generated from the hidden state representing one amino acid. For example, GCU, GCC, GCA, and GCG are outputted from the hidden state that represents Alanine. Non-\n","coding k-mers will emit from the additional state."],"metadata":{"id":"uA9eIA978AES"}},{"cell_type":"code","source":["def codon_to_state(codon): # mapping\n","    if codon in [\"AAA\", \"AAG\"]:\n","        return 0   # Lizyna\n","    elif codon in [\"GCU\", \"GCC\", \"GCA\", \"GCG\"]:\n","        return 1   # Alanina\n","    elif codon in [\"AAU\", \"AAC\"]:\n","        return 2   # Asparagina\n","    elif codon in [\"GAU\", \"GAC\"]:\n","        return 3   # Kwas asparaginowy\n","    elif codon in [\"UUU\", \"UUC\"]:\n","        return 4   # Fenyloalanina\n","    elif codon in [\"UGU\", \"UGC\"]:\n","        return 5   # Cysteina\n","    elif codon == \"UGG\":\n","        return 6   # Tryptofan\n","    elif codon in [\"UAU\", \"UAC\"]:\n","        return 7   # Tyrozyna\n","    elif codon in [\"CAU\", \"CAC\"]:\n","        return 8   # Histydyna\n","    elif codon in [\"CCU\", \"CCC\", \"CCA\", \"CCG\"]:\n","        return 9   # Prolina\n","    elif codon in [\"ACU\", \"ACC\", \"ACA\", \"ACG\"]:\n","        return 10  # Treonina\n","    elif codon in [\"UCU\", \"UCC\", \"UCA\", \"UCG\", \"AGU\", \"AGC\"]:\n","        return 11  # Seryna\n","    elif codon in [\"CGU\", \"CGC\", \"CGA\", \"CGG\", \"AGA\", \"AGG\"]:\n","        return 12  # Arginina\n","    elif codon in [\"GGU\", \"GGC\", \"GGA\", \"GGG\"]:\n","        return 13  # Glicyna\n","    elif codon in [\"GUU\", \"GUC\", \"GUA\", \"GUG\"]:\n","        return 14  # Walina\n","    elif codon in [\"AUU\", \"AUC\", \"AUA\"]:\n","        return 15  # Izoleucyna\n","    elif codon == \"AUG\":\n","        return 16  # Metionina\n","    elif codon in [\"UUA\", \"UUG\", \"CUU\", \"CUC\", \"CUA\", \"CUG\"]:\n","        return 17  # Leucyna\n","    elif codon in [\"GAA\", \"GAG\"]:\n","        return 18  # Kwas glutaminowy\n","    elif codon in [\"CAA\", \"CAG\"]:\n","        return 19  # Glutamina\n","    elif codon in [\"UAA\", \"UAG\", \"UGA\"]:\n","        return 20  # Stop\n","    else:\n","        return 20  # Inne (non-coding)\n","\n","# every possible kmer enumerated\n","all_codons = []\n","nucleotydy = [\"A\", \"C\", \"G\", \"T\"]\n","for a in nucleotydy:\n","    for b in nucleotydy:\n","        for c in nucleotydy:\n","            all_codons.append(a + b + c)\n","\n","codon_to_index = {codon: i for i, codon in enumerate(all_codons)}\n","n_codons = len(codon_to_index)"],"metadata":{"id":"vq3J9hZ249Hu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build Probability Tables\n","\n","• While calculating the following probabilities, use pseudo-counts, i.e., start counting from\n","1 instead of 0, to avoid zero probabilities.\n","\n","3.1 Prior Probabilities (Initial State Probabilities):\n","\n","• Calculate the probability of each state (20 amino acids + 1 non-coding state) being the first\n","state.\n","\n","• Count the occurrences of the first k-mer in each sequence and map them to their respective\n","state.\n","\n","• Normalize the counts by dividing each count by the total number of sequences."],"metadata":{"id":"YH-Jju8P8Szs"}},{"cell_type":"code","source":["def compute_startprob(kmers_list, n_states=21): # count probability of the given state being the first in sequence\n","    start_counts = np.ones(n_states)\n","    total = n_states\n","\n","    for (seq_id, kmers) in kmers_list:\n","        if len(kmers) > 0:\n","            first_state = codon_to_state(kmers[0])\n","            start_counts[first_state] += 1\n","            total += 1\n","\n","    return start_counts / total\n","\n","startprob_exon = compute_startprob(train_exons_kmers, 21)\n","startprob_intron = compute_startprob(train_introns_kmers, 21)\n","\n","def print_startprob(startprob, label):\n","    print(f'Start Probabilities for {label} Model:')\n","    for state, prob in enumerate(startprob):\n","        print(f'State {state}: {prob:.6f}')\n","    print()\n","\n","\n","print_startprob(startprob_exon, \"Exon\")\n","print_startprob(startprob_intron, \"Intron\")\n"],"metadata":{"id":"bwybLfDZ5o2_","executionInfo":{"status":"ok","timestamp":1736535621155,"user_tz":-60,"elapsed":663,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"402239d5-9353-4847-ba2b-b53b5058d9a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start Probabilities for Exon Model:\n","State 0: 0.036081\n","State 1: 0.071077\n","State 2: 0.041829\n","State 3: 0.032111\n","State 4: 0.039890\n","State 5: 0.023846\n","State 6: 0.010434\n","State 7: 0.017059\n","State 8: 0.030010\n","State 9: 0.045961\n","State 10: 0.056626\n","State 11: 0.085436\n","State 12: 0.057204\n","State 13: 0.039613\n","State 14: 0.091738\n","State 15: 0.093492\n","State 16: 0.033265\n","State 17: 0.106558\n","State 18: 0.035366\n","State 19: 0.031764\n","State 20: 0.020638\n","\n","Start Probabilities for Intron Model:\n","State 0: 0.000036\n","State 1: 0.008949\n","State 2: 0.000036\n","State 3: 0.000036\n","State 4: 0.000072\n","State 5: 0.000036\n","State 6: 0.000036\n","State 7: 0.000036\n","State 8: 0.000036\n","State 9: 0.000036\n","State 10: 0.000036\n","State 11: 0.000036\n","State 12: 0.000036\n","State 13: 0.000036\n","State 14: 0.989933\n","State 15: 0.000217\n","State 16: 0.000036\n","State 17: 0.000036\n","State 18: 0.000144\n","State 19: 0.000036\n","State 20: 0.000144\n","\n"]}]},{"cell_type":"markdown","source":["3.2 Emission Probabilities:\n","\n","• Compute the probability of each codon being emitted by its corresponding state.\n","\n","• Count the frequency of each codon (trimer) for each state (20 amino acids + 1 non-coding\n","state) and use pseudo-counts.\n","\n","• Normalize the counts by dividing each count by the total counts for the respective state.\n","\n","• Ensure the emission table is a 21 x M matrix, where M is the total number of possible\n","codons (64)."],"metadata":{"id":"wBkxhURH8okM"}},{"cell_type":"code","source":["def compute_emissionprob(kmers_list, n_states=21, n_codons=64): # count how many times given state emits given codon\n","    emission_counts = np.ones((n_states, n_codons))\n","\n","    for (seq_id, kmers) in kmers_list:\n","        for kmer in kmers:\n","            s = codon_to_state(kmer)\n","            idx = codon_to_index.get(kmer, -1)\n","            if idx != -1:\n","                emission_counts[s, idx] += 1\n","\n","    emissionprob = emission_counts / emission_counts.sum(axis=1, keepdims=True)\n","    return emissionprob\n","\n","emission_exon = compute_emissionprob(train_exons_kmers, 21, n_codons)\n","emission_intron = compute_emissionprob(train_introns_kmers, 21, n_codons)\n","\n","\n","def print_emissionprob_simple(emissionprob, label=\"\"):\n","    n_states, n_codons = emissionprob.shape\n","    columns = [f\"Col{j}\" for j in range(n_codons)]\n","    index = [f\"State{i}\" for i in range(n_states)]\n","\n","    df = pd.DataFrame(emissionprob, index=index, columns=columns)\n","    print(f\"Emission Probabilities for {label} Model (shape = {emissionprob.shape}):\")\n","    print(df.round(4))\n","\n","print_emissionprob_simple(emission_exon, label=\"Exon\")\n","\n","print_emissionprob_simple(emission_intron, label=\"Intron\")\n"],"metadata":{"id":"eNAuLrCi5FTq","executionInfo":{"status":"ok","timestamp":1736535666246,"user_tz":-60,"elapsed":45093,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8da4adff-1a56-4c86-ecae-ce50a77a7dcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Emission Probabilities for Exon Model (shape = (21, 64)):\n","           Col0    Col1    Col2    Col3    Col4    Col5    Col6    Col7  \\\n","State0   0.5966  0.0000  0.4033  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State1   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State2   0.0000  0.9998  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State3   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State4   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State5   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State6   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State7   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State8   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State9   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State10  0.0000  0.0000  0.0000  0.0000  0.4084  0.2996  0.2919  0.0000   \n","State11  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State12  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State13  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State14  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State15  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State16  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State17  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State19  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State20  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","\n","           Col8    Col9  ...   Col54   Col55   Col56   Col57   Col58   Col59  \\\n","State0   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State1   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State2   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State3   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State4   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State5   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State6   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State7   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State8   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State9   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State10  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State11  0.0000  0.9998  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State12  0.2043  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State13  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State14  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State15  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State16  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State17  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State18  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State19  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State20  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","\n","          Col60   Col61   Col62   Col63  \n","State0   0.0000  0.0000  0.0000  0.0000  \n","State1   0.0000  0.0000  0.0000  0.0000  \n","State2   0.0000  0.0000  0.0000  0.0000  \n","State3   0.0000  0.0000  0.0000  0.0000  \n","State4   0.0156  0.0156  0.0156  0.0156  \n","State5   0.0156  0.0156  0.0156  0.0156  \n","State6   0.0156  0.0156  0.0156  0.0156  \n","State7   0.0156  0.0156  0.0156  0.0156  \n","State8   0.0000  0.0000  0.0000  0.0000  \n","State9   0.0000  0.0000  0.0000  0.0000  \n","State10  0.0000  0.0000  0.0000  0.0000  \n","State11  0.0000  0.0000  0.0000  0.0000  \n","State12  0.0000  0.0000  0.0000  0.0000  \n","State13  0.0000  0.0000  0.0000  0.0000  \n","State14  0.0156  0.0156  0.0156  0.0156  \n","State15  0.0156  0.0156  0.0156  0.0156  \n","State16  0.0156  0.0156  0.0156  0.0156  \n","State17  0.0156  0.0156  0.0156  0.0156  \n","State18  0.0000  0.0000  0.0000  0.0000  \n","State19  0.0000  0.0000  0.0000  0.0000  \n","State20  0.0156  0.0156  0.0156  0.0156  \n","\n","[21 rows x 64 columns]\n","Emission Probabilities for Intron Model (shape = (21, 64)):\n","           Col0    Col1    Col2    Col3    Col4    Col5    Col6    Col7  \\\n","State0   0.7040  0.0000  0.2957  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State1   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State2   0.0000  0.9992  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State3   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State4   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State5   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State6   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State7   0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State8   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State9   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State10  0.0000  0.0000  0.0000  0.0000  0.5238  0.2938  0.1820  0.0000   \n","State11  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State12  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State13  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State14  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State15  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State16  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State17  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State19  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State20  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","\n","           Col8    Col9  ...   Col54   Col55   Col56   Col57   Col58   Col59  \\\n","State0   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State1   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State2   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State3   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State4   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State5   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State6   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State7   0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State8   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State9   0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State10  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State11  0.0000  0.9985  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State12  0.3173  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State13  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State14  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State15  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State16  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State17  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","State18  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State19  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n","State20  0.0156  0.0156  ...  0.0156  0.0156  0.0156  0.0156  0.0156  0.0156   \n","\n","          Col60   Col61   Col62   Col63  \n","State0   0.0000  0.0000  0.0000  0.0000  \n","State1   0.0000  0.0000  0.0000  0.0000  \n","State2   0.0000  0.0000  0.0000  0.0000  \n","State3   0.0000  0.0000  0.0000  0.0000  \n","State4   0.0156  0.0156  0.0156  0.0156  \n","State5   0.0156  0.0156  0.0156  0.0156  \n","State6   0.0156  0.0156  0.0156  0.0156  \n","State7   0.0156  0.0156  0.0156  0.0156  \n","State8   0.0000  0.0000  0.0000  0.0000  \n","State9   0.0000  0.0000  0.0000  0.0000  \n","State10  0.0000  0.0000  0.0000  0.0000  \n","State11  0.0000  0.0000  0.0000  0.0000  \n","State12  0.0000  0.0000  0.0000  0.0000  \n","State13  0.0000  0.0000  0.0000  0.0000  \n","State14  0.0156  0.0156  0.0156  0.0156  \n","State15  0.0156  0.0156  0.0156  0.0156  \n","State16  0.0156  0.0156  0.0156  0.0156  \n","State17  0.0156  0.0156  0.0156  0.0156  \n","State18  0.0000  0.0000  0.0000  0.0000  \n","State19  0.0000  0.0000  0.0000  0.0000  \n","State20  0.0156  0.0156  0.0156  0.0156  \n","\n","[21 rows x 64 columns]\n"]}]},{"cell_type":"markdown","source":["3.3 Transition Probabilities:\n","\n","• Calculate the probability of transitioning from one state to another.\n","\n","• Count the occurrences where one state (amino acid or non-coding) is followed by another\n","and use pseudo-counts.\n","\n","• Normalize the counts by dividing each count by the total transitions from the originating\n","state, i.e., divide each entry in a row by the sum of the row.\n","\n","• Ensure the transition table is a 21 x 21 matrix, representing transitions between all states."],"metadata":{"id":"-cfQW2nU81IW"}},{"cell_type":"code","source":["def compute_transitionprob(kmers_list, n_states=21): # count transition state to state\n","    trans_counts = np.ones((n_states, n_states))\n","\n","    for (seq_id, kmers) in kmers_list:\n","        for i in range(len(kmers) - 1):\n","            s_current = codon_to_state(kmers[i])\n","            s_next    = codon_to_state(kmers[i + 1])\n","            trans_counts[s_current, s_next] += 1\n","\n","    transmat = trans_counts / trans_counts.sum(axis=1, keepdims=True)\n","    return transmat\n","\n","\n","transmat_exon = compute_transitionprob(train_exons_kmers, 21)\n","transmat_intron = compute_transitionprob(train_introns_kmers, 21)\n","\n","\n","def print_transitionprob(transitionprob, label, n_states=21):\n","    state_labels = []\n","    for i in range(n_states):\n","        state_label = \"State \" + str(i)\n","        state_labels.append(state_label)\n","\n","    df = pd.DataFrame(\n","        transitionprob,\n","        index=state_labels,\n","        columns=state_labels\n","    )\n","\n","    print(f\"Transition Probabilities for {label} Model:\")\n","    print(df)\n","\n","print_transitionprob(transmat_exon, \"Exon\")\n","print_transitionprob(transmat_intron, \"Intron\")\n"],"metadata":{"id":"wOQ40Aow5jvh","executionInfo":{"status":"ok","timestamp":1736535719329,"user_tz":-60,"elapsed":53094,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cb960bb-a3aa-461d-dc79-7b7ce77a5f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transition Probabilities for Exon Model:\n","               State 0       State 1       State 2       State 3  \\\n","State 0   3.236137e-01  1.466226e-06  2.763734e-01  1.466226e-06   \n","State 1   9.921058e-07  9.921058e-07  9.921058e-07  9.921058e-07   \n","State 2   1.800488e-06  1.800488e-06  1.800488e-06  1.800488e-06   \n","State 3   2.350563e-06  2.350563e-06  2.350563e-06  2.350563e-06   \n","State 4   1.926348e-06  1.926348e-06  1.926348e-06  1.926348e-06   \n","State 5   2.109794e-06  5.694797e-01  2.109794e-06  2.109794e-06   \n","State 6   3.654477e-06  3.654477e-06  3.654477e-06  3.654477e-06   \n","State 7   2.778295e-06  2.778295e-06  2.778295e-06  2.778295e-06   \n","State 8   2.151153e-06  2.151153e-06  2.151153e-06  2.151153e-06   \n","State 9   1.193594e-06  1.193594e-06  1.193594e-06  1.193594e-06   \n","State 10  1.179252e-06  1.179252e-06  1.179252e-06  1.179252e-06   \n","State 11  7.726781e-07  2.139901e-01  7.726781e-07  7.726781e-07   \n","State 12  8.152398e-07  1.792916e-01  8.152398e-07  1.697794e-01   \n","State 13  1.260687e-06  3.023179e-01  1.260687e-06  1.532139e-01   \n","State 14  1.437521e-06  1.437521e-06  1.437521e-06  1.437521e-06   \n","State 15  1.382256e-06  1.382256e-06  1.382256e-06  1.382256e-06   \n","State 16  4.225150e-06  4.225150e-06  4.225150e-06  4.225150e-06   \n","State 17  8.526705e-07  8.526705e-07  8.526705e-07  8.526705e-07   \n","State 18  3.150467e-01  1.879731e-06  2.250752e-01  1.879731e-06   \n","State 19  3.005524e-01  1.598938e-06  2.599842e-01  1.598938e-06   \n","State 20  2.205700e-01  2.006988e-06  1.705157e-01  1.908967e-01   \n","\n","               State 4       State 5       State 6       State 7  \\\n","State 0   1.466226e-06  1.466226e-06  1.466226e-06  1.466226e-06   \n","State 1   9.921058e-07  9.921058e-07  9.921058e-07  9.921058e-07   \n","State 2   1.800488e-06  1.800488e-06  1.800488e-06  1.800488e-06   \n","State 3   2.350563e-06  2.350563e-06  2.350563e-06  2.350563e-06   \n","State 4   2.935504e-01  1.926348e-06  1.926348e-06  1.926348e-06   \n","State 5   2.109794e-06  2.109794e-06  2.109794e-06  2.109794e-06   \n","State 6   3.654477e-06  3.654477e-06  3.654477e-06  3.654477e-06   \n","State 7   2.778295e-06  2.778295e-06  2.778295e-06  2.778295e-06   \n","State 8   2.151153e-06  2.151153e-06  2.151153e-06  2.151153e-06   \n","State 9   1.193594e-06  1.193594e-06  1.193594e-06  1.193594e-06   \n","State 10  1.179252e-06  1.179252e-06  1.179252e-06  1.179252e-06   \n","State 11  7.726781e-07  7.726781e-07  7.726781e-07  7.726781e-07   \n","State 12  8.152398e-07  8.152398e-07  8.152398e-07  8.152398e-07   \n","State 13  1.260687e-06  1.260687e-06  1.260687e-06  1.260687e-06   \n","State 14  1.549475e-01  1.583286e-01  1.050526e-01  9.784343e-02   \n","State 15  1.975672e-01  1.382256e-06  1.382256e-06  1.571349e-01   \n","State 16  4.225150e-06  4.938482e-01  2.529470e-01  4.225150e-06   \n","State 17  9.851669e-02  2.104331e-01  1.205582e-01  1.522042e-01   \n","State 18  1.879731e-06  1.879731e-06  1.879731e-06  1.879731e-06   \n","State 19  1.598938e-06  1.598938e-06  1.598938e-06  1.598938e-06   \n","State 20  2.006988e-06  2.006988e-06  2.006988e-06  2.006988e-06   \n","\n","               State 8       State 9  ...      State 11      State 12  \\\n","State 0   1.466226e-06  1.466226e-06  ...  1.968687e-01  2.031192e-01   \n","State 1   1.162202e-01  2.623624e-01  ...  9.921058e-07  2.151947e-01   \n","State 2   1.800488e-06  1.800488e-06  ...  1.800488e-06  1.800488e-06   \n","State 3   2.350563e-06  2.350563e-06  ...  2.350563e-06  2.350563e-06   \n","State 4   1.926348e-06  1.926348e-06  ...  4.402996e-01  1.926348e-06   \n","State 5   2.109794e-06  2.109794e-06  ...  2.109794e-06  2.109794e-06   \n","State 6   3.654477e-06  3.654477e-06  ...  3.654477e-06  3.654477e-06   \n","State 7   2.778295e-06  2.778295e-06  ...  2.778295e-06  2.778295e-06   \n","State 8   2.151153e-06  2.151153e-06  ...  2.151153e-06  2.151153e-06   \n","State 9   1.611089e-01  1.960752e-01  ...  1.193594e-06  2.358792e-01   \n","State 10  1.381836e-01  2.316370e-01  ...  1.179252e-06  2.247336e-01   \n","State 11  7.368567e-02  1.637606e-01  ...  7.726781e-07  1.607959e-01   \n","State 12  8.152398e-07  8.152398e-07  ...  8.152398e-07  8.152398e-07   \n","State 13  1.260687e-06  1.260687e-06  ...  1.260687e-06  1.260687e-06   \n","State 14  1.437521e-06  1.437521e-06  ...  2.342814e-01  1.437521e-06   \n","State 15  1.382256e-06  1.382256e-06  ...  3.477576e-01  1.382256e-06   \n","State 16  4.225150e-06  4.225150e-06  ...  4.225150e-06  4.225150e-06   \n","State 17  8.526705e-07  8.526705e-07  ...  1.512177e-01  8.526705e-07   \n","State 18  1.879731e-06  1.879731e-06  ...  2.214549e-01  2.383913e-01   \n","State 19  1.598938e-06  1.598938e-06  ...  2.638136e-01  1.756226e-01   \n","State 20  2.006988e-06  2.006988e-06  ...  1.113016e-01  7.733930e-02   \n","\n","              State 13      State 14      State 15      State 16  \\\n","State 0   1.466226e-06  1.466226e-06  1.466226e-06  1.466226e-06   \n","State 1   9.921058e-07  9.921058e-07  9.921058e-07  9.921058e-07   \n","State 2   1.800488e-06  1.800488e-06  3.951063e-01  1.306632e-01   \n","State 3   2.350563e-06  2.350563e-06  3.901088e-01  1.653598e-01   \n","State 4   1.926348e-06  1.926348e-06  1.926348e-06  1.926348e-06   \n","State 5   2.109794e-06  4.304802e-01  2.109794e-06  2.109794e-06   \n","State 6   9.999269e-01  3.654477e-06  3.654477e-06  3.654477e-06   \n","State 7   2.778295e-06  2.778295e-06  4.255375e-01  1.178358e-01   \n","State 8   2.151153e-06  2.151153e-06  3.920390e-01  1.108339e-01   \n","State 9   1.193594e-06  1.193594e-06  1.193594e-06  1.193594e-06   \n","State 10  1.179252e-06  1.179252e-06  1.179252e-06  1.179252e-06   \n","State 11  7.726781e-07  1.518343e-01  7.726781e-07  7.726781e-07   \n","State 12  3.181286e-01  1.197799e-01  8.152398e-07  8.152398e-07   \n","State 13  1.622782e-01  1.833443e-01  1.260687e-06  1.260687e-06   \n","State 14  1.437521e-06  1.437521e-06  1.437521e-06  1.437521e-06   \n","State 15  1.382256e-06  1.382256e-06  1.382256e-06  1.382256e-06   \n","State 16  4.225150e-06  4.225150e-06  4.225150e-06  4.225150e-06   \n","State 17  8.526705e-07  8.526705e-07  8.526705e-07  8.526705e-07   \n","State 18  1.879731e-06  1.879731e-06  1.879731e-06  1.879731e-06   \n","State 19  1.598938e-06  1.598938e-06  1.598938e-06  1.598938e-06   \n","State 20  2.006988e-06  2.006988e-06  2.006988e-06  2.006988e-06   \n","\n","              State 17      State 18      State 19      State 20  \n","State 0   1.466226e-06  1.466226e-06  1.466226e-06  1.466226e-06  \n","State 1   2.233270e-01  9.921058e-07  1.828798e-01  9.921058e-07  \n","State 2   1.800488e-06  1.800488e-06  1.800488e-06  1.800488e-06  \n","State 3   2.350563e-06  2.350563e-06  2.350563e-06  2.350563e-06  \n","State 4   2.661153e-01  1.926348e-06  1.926348e-06  1.926348e-06  \n","State 5   2.109794e-06  2.109794e-06  2.109794e-06  2.109794e-06  \n","State 6   3.654477e-06  3.654477e-06  3.654477e-06  3.654477e-06  \n","State 7   2.778295e-06  2.778295e-06  2.778295e-06  2.778295e-06  \n","State 8   2.151153e-06  2.151153e-06  2.151153e-06  2.151153e-06  \n","State 9   2.073105e-01  1.193594e-06  1.996071e-01  1.193594e-06  \n","State 10  2.276676e-01  1.179252e-06  1.777593e-01  1.179252e-06  \n","State 11  1.378295e-01  7.726781e-07  9.809303e-02  7.726781e-07  \n","State 12  8.152398e-07  2.130075e-01  8.152398e-07  8.152398e-07  \n","State 13  1.260687e-06  1.988255e-01  1.260687e-06  1.260687e-06  \n","State 14  1.098036e-01  1.437521e-06  1.437521e-06  1.397227e-01  \n","State 15  1.636425e-01  1.382256e-06  1.382256e-06  1.338756e-01  \n","State 16  4.225150e-06  4.225150e-06  4.225150e-06  2.531287e-01  \n","State 17  5.796369e-02  8.526705e-07  8.526705e-07  2.090944e-01  \n","State 18  1.879731e-06  1.879731e-06  1.879731e-06  1.879731e-06  \n","State 19  1.598938e-06  1.598938e-06  1.598938e-06  1.598938e-06  \n","State 20  2.006988e-06  2.293466e-01  2.006988e-06  2.006988e-06  \n","\n","[21 rows x 21 columns]\n","Transition Probabilities for Intron Model:\n","           State 0   State 1   State 2   State 3   State 4   State 5  \\\n","State 0   0.357972  0.000004  0.351242  0.000004  0.000004  0.000004   \n","State 1   0.000006  0.000006  0.000006  0.000006  0.000006  0.000006   \n","State 2   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005   \n","State 3   0.000012  0.000012  0.000012  0.000012  0.000012  0.000012   \n","State 4   0.000003  0.000003  0.000003  0.000003  0.397277  0.000003   \n","State 5   0.000007  0.430592  0.000007  0.000007  0.000007  0.000007   \n","State 6   0.000023  0.000023  0.000023  0.000023  0.000023  0.000023   \n","State 7   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005   \n","State 8   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008   \n","State 9   0.000006  0.000006  0.000006  0.000006  0.000006  0.000006   \n","State 10  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005   \n","State 11  0.000003  0.120860  0.000003  0.000003  0.000003  0.000003   \n","State 12  0.000005  0.149244  0.000005  0.211091  0.000005  0.000005   \n","State 13  0.000009  0.246250  0.000009  0.125397  0.000009  0.000009   \n","State 14  0.000004  0.000004  0.000004  0.000004  0.193308  0.117205   \n","State 15  0.000003  0.000003  0.000003  0.000003  0.258575  0.000003   \n","State 16  0.000015  0.000015  0.000015  0.000015  0.000015  0.572367   \n","State 17  0.000002  0.000002  0.000002  0.000002  0.109795  0.169280   \n","State 18  0.357133  0.000010  0.299765  0.000010  0.000010  0.000010   \n","State 19  0.361148  0.000008  0.342963  0.000008  0.000008  0.000008   \n","State 20  0.280201  0.000004  0.259116  0.123904  0.000004  0.000004   \n","\n","           State 6   State 7   State 8   State 9  ...  State 11  State 12  \\\n","State 0   0.000004  0.000004  0.000004  0.000004  ...  0.174744  0.115970   \n","State 1   0.000006  0.000006  0.159065  0.210532  ...  0.000006  0.142629   \n","State 2   0.000005  0.000005  0.000005  0.000005  ...  0.000005  0.000005   \n","State 3   0.000012  0.000012  0.000012  0.000012  ...  0.000012  0.000012   \n","State 4   0.000003  0.000003  0.000003  0.000003  ...  0.309414  0.000003   \n","State 5   0.000007  0.000007  0.000007  0.000007  ...  0.000007  0.000007   \n","State 6   0.000023  0.000023  0.000023  0.000023  ...  0.000023  0.000023   \n","State 7   0.000005  0.000005  0.000005  0.000005  ...  0.000005  0.000005   \n","State 8   0.000008  0.000008  0.000008  0.000008  ...  0.000008  0.000008   \n","State 9   0.000006  0.000006  0.188873  0.229033  ...  0.000006  0.145368   \n","State 10  0.000005  0.000005  0.176187  0.199035  ...  0.000005  0.123293   \n","State 11  0.000003  0.000003  0.099199  0.161151  ...  0.000003  0.110804   \n","State 12  0.000005  0.000005  0.000005  0.000005  ...  0.000005  0.000005   \n","State 13  0.000009  0.000009  0.000009  0.000009  ...  0.000009  0.000009   \n","State 14  0.043013  0.130544  0.000004  0.000004  ...  0.137933  0.000004   \n","State 15  0.000003  0.197450  0.000003  0.000003  ...  0.203246  0.000003   \n","State 16  0.166396  0.000015  0.000015  0.000015  ...  0.000015  0.000015   \n","State 17  0.049393  0.201800  0.000002  0.000002  ...  0.098816  0.000002   \n","State 18  0.000010  0.000010  0.000010  0.000010  ...  0.212231  0.130705   \n","State 19  0.000008  0.000008  0.000008  0.000008  ...  0.173742  0.122008   \n","State 20  0.000004  0.000004  0.000004  0.000004  ...  0.099157  0.080217   \n","\n","          State 13  State 14  State 15  State 16  State 17  State 18  \\\n","State 0   0.000004  0.000004  0.000004  0.000004  0.000004  0.000004   \n","State 1   0.000006  0.000006  0.000006  0.000006  0.292461  0.000006   \n","State 2   0.000005  0.000005  0.535142  0.116658  0.000005  0.000005   \n","State 3   0.000012  0.000012  0.564960  0.108211  0.000012  0.000012   \n","State 4   0.000003  0.000003  0.000003  0.000003  0.293248  0.000003   \n","State 5   0.000007  0.569277  0.000007  0.000007  0.000007  0.000007   \n","State 6   0.999549  0.000023  0.000023  0.000023  0.000023  0.000023   \n","State 7   0.000005  0.000005  0.581061  0.111008  0.000005  0.000005   \n","State 8   0.000008  0.000008  0.519362  0.086011  0.000008  0.000008   \n","State 9   0.000006  0.000006  0.000006  0.000006  0.256014  0.000006   \n","State 10  0.000005  0.000005  0.000005  0.000005  0.322772  0.000005   \n","State 11  0.000003  0.187858  0.000003  0.000003  0.212162  0.000003   \n","State 12  0.230789  0.164790  0.000005  0.000005  0.000005  0.244003   \n","State 13  0.205160  0.269021  0.000009  0.000009  0.000009  0.154028   \n","State 14  0.000004  0.000004  0.000004  0.000004  0.136211  0.000004   \n","State 15  0.000003  0.000003  0.000003  0.000003  0.186713  0.000003   \n","State 16  0.000015  0.000015  0.000015  0.000015  0.000015  0.000015   \n","State 17  0.000002  0.000002  0.000002  0.000002  0.081337  0.000002   \n","State 18  0.000010  0.000010  0.000010  0.000010  0.000010  0.000010   \n","State 19  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008   \n","State 20  0.000004  0.000004  0.000004  0.000004  0.000008  0.156176   \n","\n","          State 19  State 20  \n","State 0   0.000004  0.000004  \n","State 1   0.195214  0.000006  \n","State 2   0.000005  0.000005  \n","State 3   0.000012  0.000012  \n","State 4   0.000003  0.000006  \n","State 5   0.000007  0.000007  \n","State 6   0.000023  0.000023  \n","State 7   0.000005  0.000005  \n","State 8   0.000008  0.000008  \n","State 9   0.180620  0.000006  \n","State 10  0.178640  0.000005  \n","State 11  0.107927  0.000003  \n","State 12  0.000005  0.000005  \n","State 13  0.000009  0.000009  \n","State 14  0.000004  0.241728  \n","State 15  0.000003  0.153970  \n","State 16  0.000015  0.260972  \n","State 17  0.000002  0.289548  \n","State 18  0.000010  0.000010  \n","State 19  0.000008  0.000008  \n","State 20  0.000004  0.001171  \n","\n","[21 rows x 21 columns]\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# Train the HMMs\n","4.1 Train (i.e., calculate the above three probability tables) two separate HMMs using\n","the hmmlearn library:\n","\n","• One HMM for exon sequences (three probability tables obtained from the exons).\n","\n","• One HMM for intron sequences (three probability tables obtained from the introns).\n","\n","• Students should initialize a Multinomial HMM with their calculated prior, transition,\n","and emission probabilities.\n","\n","4.2 Use the calculated prior, emission, and transition probabilities to initialize the models. Ensure\n","that the dimensions of the probability tables match the requirements of hmmlearn:\n","\n","• Start probabilities: A 1D array of size 21.\n","\n","• Transition probabilities: A 2D array of size 21 x 21.\n","\n","• Emission probabilities: A 2D array of size 21 x 64."],"metadata":{"id":"QOBkAG2V9AAG"}},{"cell_type":"code","source":["hmm_exon = hmm.MultinomialHMM(\n","    n_components=21,\n","    n_trials=1,\n","    init_params='',\n","    n_iter=1,\n","    random_state=42\n",")\n","\n","hmm_intron = hmm.MultinomialHMM(\n","    n_components=21,\n","    n_trials=1,\n","    init_params='',\n","    n_iter=1,\n","    random_state=42\n",")\n","\n","hmm_exon.startprob_= startprob_exon\n","hmm_exon.transmat_ = transmat_exon\n","hmm_exon.emissionprob_ = emission_exon\n","\n","hmm_intron.startprob_ = startprob_intron\n","hmm_intron.transmat_ = transmat_intron\n","hmm_intron.emissionprob_ = emission_intron\n","\n","\n","print(f\"Start Probabilities Shape: {hmm_exon.startprob_.shape}\")\n","print(f\"Transition Matrix Shape: {hmm_exon.transmat_.shape}\")\n","print(f\"Emission Matrix Shape: {hmm_exon.emissionprob_.shape}\\n\")\n","\n","\n","print(f\"Start Probabilities Shape: {hmm_intron.startprob_.shape}\")\n","print(f\"Transition Matrix Shape: {hmm_intron.transmat_.shape}\")\n","print(f\"Emission Matrix Shape: {hmm_intron.emissionprob_.shape}\\n\")"],"metadata":{"id":"9MZPhv8R4XaT","executionInfo":{"status":"ok","timestamp":1736535719329,"user_tz":-60,"elapsed":21,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1aaaff45-1aef-4ca7-e308-22f3a5b7ca1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n","https://github.com/hmmlearn/hmmlearn/issues/335\n","https://github.com/hmmlearn/hmmlearn/issues/340\n","WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n","https://github.com/hmmlearn/hmmlearn/issues/335\n","https://github.com/hmmlearn/hmmlearn/issues/340\n"]},{"output_type":"stream","name":"stdout","text":["Start Probabilities Shape: (21,)\n","Transition Matrix Shape: (21, 21)\n","Emission Matrix Shape: (21, 64)\n","\n","Start Probabilities Shape: (21,)\n","Transition Matrix Shape: (21, 21)\n","Emission Matrix Shape: (21, 64)\n","\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# Classification\n","5.1 For each sequence in a set (training, validation, and testing):\n","\n","• Compute the log-likelihood of the sequence under both the exon HMM and the intron\n","HMM using the score method.\n","\n","• Assign the sequence the label of the model (exon or intron) with the higher log-likelihood.\n","\n","5.2 Each unique k-mer must be assigned a numeric index, creating a mapping (e.g., {\"ATG\": 0,\n","\"TGC\": 1, \"GCA\": 2}) that aligns with the emission probability matrix. Once the mapping is\n","established, a k-mer sequence can be converted to a series of indices by replacing each k-mer with\n","its corresponding value from the mapping. The resulting sequence of indices should be reshaped\n","into a column vector (e.g., np.array([0, 1, 2]).reshape(-1, 1)) and passed to the HMM’s score\n","method to compute the log-likelihood."],"metadata":{"id":"IBXh93LX9NhY"}},{"cell_type":"code","source":["def one_hot_encode(idx, length=64): # generates 64 dim one-hot vector for kmers\n","    v = np.zeros(length, dtype=int)\n","    v[idx] = 1\n","    return v\n","\n","def classify_sequence(kmers, model_exon, model_intron): # score method computes log likelihood on the matrix made of one-hot vectors\n","    onehot_rows = []\n","    for kmer in kmers:\n","        idx = codon_to_index.get(kmer, -1)\n","        if idx == -1:\n","            continue\n","        v = one_hot_encode(idx, 64)\n","        onehot_rows.append(v)\n","\n","    if len(onehot_rows) == 0:\n","        return \"Unknown\"\n","\n","    X_test = np.array(onehot_rows, dtype=int)\n","\n","    ll_exon   = model_exon.score(X_test)\n","    ll_intron = model_intron.score(X_test)\n","\n","    return \"Exon\" if ll_exon > ll_intron else \"Intron\" # comapring log likelihood fromintron and exom models\n"],"metadata":{"id":"iJEBYyS77Uc5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# Evaluation\n","\n","6.1 Compute the classification accuracy, precision, recall, and F1-score on:\n","• The training set.\n","• The validation set.\n","• The testing set.\n"],"metadata":{"id":"x-x3y5Y69iqG"}},{"cell_type":"code","source":["def evaluate_classification(exons_kmers, introns_kmers, model_exon, model_intron):\n","    predictions = []\n","    true_labels = []\n","\n","    total = len(exons_kmers) + len(introns_kmers)\n","    count = 0\n","\n","    for (seq_id, kmers) in exons_kmers:\n","        pred = classify_sequence(kmers, model_exon, model_intron)\n","        predictions.append(pred)\n","        true_labels.append(\"Exon\")\n","        count += 1\n","        if count % 1000 == 0:\n","            print(f\"Processed {count}/{total} sequences...\")\n","\n","    for (seq_id, kmers) in introns_kmers:\n","        pred = classify_sequence(kmers, model_exon, model_intron)\n","        predictions.append(pred)\n","        true_labels.append(\"Intron\")\n","        count += 1\n","        if count % 1000 == 0:\n","            print(f\"Processed {count}/{total} sequences...\")\n","\n","    acc = accuracy_score(true_labels, predictions)\n","    prec = precision_score(true_labels, predictions, average='macro')\n","    rec = recall_score(true_labels, predictions, average='macro')\n","    f1 = f1_score(true_labels, predictions, average='macro')\n","\n","\n","    results = list(zip(predictions, true_labels))\n","    return acc, prec, rec, f1, results\n"],"metadata":{"id":"hhtacana7CAU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_acc, train_prec, train_rec, train_f1, train_results = evaluate_classification(\n","    train_exons_kmers,\n","    train_introns_kmers,\n","    hmm_exon,\n","    hmm_intron\n",")\n","print(f\"Train:\")\n","print(f\"  Accuracy:  {train_acc * 100:.2f}%\")\n","print(f\"  Precision: {train_prec:.3f}\")\n","print(f\"  Recall:    {train_rec:.3f}\")\n","print(f\"  F1-score:  {train_f1:.3f}\")"],"metadata":{"id":"Ph9XFe6e7Cfq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736537706379,"user_tz":-60,"elapsed":1144803,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"outputId":"7d04b55b-de15-43ca-f1af-3d7107430504"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 1000/70990 sequences...\n","Processed 2000/70990 sequences...\n","Processed 3000/70990 sequences...\n","Processed 4000/70990 sequences...\n","Processed 5000/70990 sequences...\n","Processed 6000/70990 sequences...\n","Processed 7000/70990 sequences...\n","Processed 8000/70990 sequences...\n","Processed 9000/70990 sequences...\n","Processed 10000/70990 sequences...\n","Processed 11000/70990 sequences...\n","Processed 12000/70990 sequences...\n","Processed 13000/70990 sequences...\n","Processed 14000/70990 sequences...\n","Processed 15000/70990 sequences...\n","Processed 16000/70990 sequences...\n","Processed 17000/70990 sequences...\n","Processed 18000/70990 sequences...\n","Processed 19000/70990 sequences...\n","Processed 20000/70990 sequences...\n","Processed 21000/70990 sequences...\n","Processed 22000/70990 sequences...\n","Processed 23000/70990 sequences...\n","Processed 24000/70990 sequences...\n","Processed 25000/70990 sequences...\n","Processed 26000/70990 sequences...\n","Processed 27000/70990 sequences...\n","Processed 28000/70990 sequences...\n","Processed 29000/70990 sequences...\n","Processed 30000/70990 sequences...\n","Processed 31000/70990 sequences...\n","Processed 32000/70990 sequences...\n","Processed 33000/70990 sequences...\n","Processed 34000/70990 sequences...\n","Processed 35000/70990 sequences...\n","Processed 36000/70990 sequences...\n","Processed 37000/70990 sequences...\n","Processed 38000/70990 sequences...\n","Processed 39000/70990 sequences...\n","Processed 40000/70990 sequences...\n","Processed 41000/70990 sequences...\n","Processed 42000/70990 sequences...\n","Processed 43000/70990 sequences...\n","Processed 44000/70990 sequences...\n","Processed 45000/70990 sequences...\n","Processed 46000/70990 sequences...\n","Processed 47000/70990 sequences...\n","Processed 48000/70990 sequences...\n","Processed 49000/70990 sequences...\n","Processed 50000/70990 sequences...\n","Processed 51000/70990 sequences...\n","Processed 52000/70990 sequences...\n","Processed 53000/70990 sequences...\n","Processed 54000/70990 sequences...\n","Processed 55000/70990 sequences...\n","Processed 56000/70990 sequences...\n","Processed 57000/70990 sequences...\n","Processed 58000/70990 sequences...\n","Processed 59000/70990 sequences...\n","Processed 60000/70990 sequences...\n","Processed 61000/70990 sequences...\n","Processed 62000/70990 sequences...\n","Processed 63000/70990 sequences...\n","Processed 64000/70990 sequences...\n","Processed 65000/70990 sequences...\n","Processed 66000/70990 sequences...\n","Processed 67000/70990 sequences...\n","Processed 68000/70990 sequences...\n","Processed 69000/70990 sequences...\n","Processed 70000/70990 sequences...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Train:\n","  Accuracy:  75.29%\n","  Precision: 0.510\n","  Recall:    0.472\n","  F1-score:  0.477\n"]}]},{"cell_type":"code","source":["val_acc, val_prec, val_rec, val_f1, val_results = evaluate_classification(\n","    val_exons_kmers,\n","    val_introns_kmers,\n","    hmm_exon,\n","    hmm_intron\n",")\n","print(f\"Validation:\")\n","print(f\"  Accuracy:  {val_acc * 100:.2f}%\")\n","print(f\"  Precision: {val_prec:.3f}\")\n","print(f\"  Recall:    {val_rec:.3f}\")\n","print(f\"  F1-score:  {val_f1:.3f}\")\n"],"metadata":{"id":"vJyEKGyLi9S7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736538079079,"user_tz":-60,"elapsed":161099,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"outputId":"89333ffc-d1e8-4ae1-d257-8372cc1a643c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 1000/20283 sequences...\n","Processed 2000/20283 sequences...\n","Processed 3000/20283 sequences...\n","Processed 4000/20283 sequences...\n","Processed 5000/20283 sequences...\n","Processed 6000/20283 sequences...\n","Processed 7000/20283 sequences...\n","Processed 8000/20283 sequences...\n","Processed 9000/20283 sequences...\n","Processed 10000/20283 sequences...\n","Processed 11000/20283 sequences...\n","Processed 12000/20283 sequences...\n","Processed 13000/20283 sequences...\n","Processed 14000/20283 sequences...\n","Processed 15000/20283 sequences...\n","Processed 16000/20283 sequences...\n","Processed 17000/20283 sequences...\n","Processed 18000/20283 sequences...\n","Processed 19000/20283 sequences...\n","Processed 20000/20283 sequences...\n","Validation:\n","  Accuracy:  75.15%\n","  Precision: 0.508\n","  Recall:    0.471\n","  F1-score:  0.476\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["test_acc, test_prec, test_rec, test_f1, test_results = evaluate_classification(\n","    test_exons_kmers,\n","    test_introns_kmers,\n","    hmm_exon,\n","    hmm_intron\n",")\n","print(f\"Tests:\")\n","print(f\"  Accuracy:  {test_acc * 100:.2f}%\")\n","print(f\"  Precision: {test_prec:.3f}\")\n","print(f\"  Recall:    {test_rec:.3f}\")\n","print(f\"  F1-score:  {test_f1:.3f}\")"],"metadata":{"id":"nYj_5j1PjAKe","executionInfo":{"status":"ok","timestamp":1736538924086,"user_tz":-60,"elapsed":175770,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8f5fcf8-19a1-41da-f9bb-75291c6b5fb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 1000/10143 sequences...\n","Processed 2000/10143 sequences...\n","Processed 3000/10143 sequences...\n","Processed 4000/10143 sequences...\n","Processed 5000/10143 sequences...\n","Processed 6000/10143 sequences...\n","Processed 7000/10143 sequences...\n","Processed 8000/10143 sequences...\n","Processed 9000/10143 sequences...\n","Processed 10000/10143 sequences...\n","Tests:\n","  Accuracy:  75.04%\n","  Precision: 0.507\n","  Recall:    0.470\n","  F1-score:  0.475\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["print(\"Sample predictions from test set:\")\n","for i, (pred, actual) in enumerate(test_results[:10]):\n","    print(f\"  Predicted: {pred}, Actual: {actual}\")"],"metadata":{"id":"LQ-kU3lXjCgh","executionInfo":{"status":"ok","timestamp":1736538924088,"user_tz":-60,"elapsed":26,"user":{"displayName":"Kristina Bujanowska","userId":"09182847461107807898"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2bf31b1c-ed6c-4752-8394-69cdcd9c790e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample predictions from test set:\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Intron, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n","  Predicted: Exon, Actual: Exon\n"]}]},{"cell_type":"markdown","source":["7. Write one Jupyter notebook for the entire assignment. Organize your notebook with\n","appropriate markdown titles and comments to make it easy to follow.\n","\n","9. Enhance notebook readability: Add markdown cells with clear titles for each major step: (i)\n","data reprocessing; (ii) model training, (iii) model evaluation and results, and (iv) conclusions.\n","Include code comments explaining your implementation.\n","\n"],"metadata":{"id":"yJUAQ_tF9qWm"}},{"cell_type":"markdown","source":["8. Summarize your observations: Include a markdown section with bullet points summarizing:\n","what you did, what you observed, and what you concluded."],"metadata":{"id":"VS2rn1HS9xAQ"}},{"cell_type":"markdown","source":["\n"," I loaded the exon and intron sequences from FASTA files and split them into three sets. Split every sequence to kmers. Function codon_to_state mapped kmers to state numbers corresponding with aminoacids. Then I calculated and printed using pandas dataframe probabilities of 1. a state being the first state, 2. each codon being emmited by a corresponding state, 3. transition from one state to another. I used pseudocount and normalized them. I initailaized 2 models, for exon and intron sequences. I used one-hot encoding because I encoutered an error about number of trials that I couldn't resolve when using indices. I must admit that this approach was suggested by chatgpt. Then computed log likelihood for each sequence in both models and classified a sequence as exon or intron based on which model gave a higher log likelihood. Using scikit learn I computed metrics.\n","\n"," The accuracy was moderate, but other metrics were low and suggested taht further oprimizations are necessary. However sampling 10 predictions show that they are mostly correct."],"metadata":{"id":"RT8T3Io-jzyR"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# Knowledge\n","1. Watch the video and read the slides about HMM.\n","2. Answer the following questions in the same Jupyter notebook that includes the classifiers\n","described above, each in one cell:\n","\n","a. Explain (in simple language) the meaning of the words: “hidden” and “Markov”\n","found in the name of this technique: Hidden Markov Models. Use the examples, I used\n","in class (hint: observing something inside a transparent box and predicting the grade\n","of a student using his/her grade history).\n","\n","b. State the Decoding Problem? Which algorithm is applied to solve the Decoding\n","Problem? What type of algorithms is it?\n","\n","c. Explain (in simple language) the Viterbi Learning algorithm (not the Viterbi\n","algorithm).\n","\n","d. How can we describe an HMM formally?\n","\n","e. Why do we prefer to work with the log probabilities to the probabilities themselves?"],"metadata":{"id":"qufGc4yu9yb5"}},{"cell_type":"markdown","source":["a. \"Hidden\" means that there is some factor that is not directly visible that controls the changes of the visible states. In example the visible states could be interchanging solid, liquid and fog in the transparent box. We do not see the temperature but it is responsible for the change.\n","\n","\"Markov\" is the surname of the russian sciencist that came up with the theroem about the condition of independence. It says that the next state is dependent on the previous state and not on the ones before it.\n"],"metadata":{"id":"4_LZCZML1Zjg"}},{"cell_type":"markdown","source":["b. Decoding Problem is about finding the best sequence of hidden states given the observation sequence. It  can be solved by using the Viterbi algorithm. It is a dynamic programming algorithm, because it breaks the big problem into more easier problems. It is simmilar to the sequence alignment table. Viterbi algorithm calculates the score for every possible move forward in the path from start to end note. The best score indicates the next node. At the end it backtracks the nodes in the best path and this is the sequence we are looking for."],"metadata":{"id":"svYVxdCZ4LXm"}},{"cell_type":"markdown","source":["c. Starting from random parameters and some emmited string run the Viterbi algorithm to find the best hidden path. Then using the hidden path and emmited string to recalculate the model. Repeat thisuntil the probabilities dont change. This way we dont have to calculate the probabilities ourselves."],"metadata":{"id":"ciy4ypoUBQ5Q"}},{"cell_type":"markdown","source":["d. The HMM is a generative probabilistic model, in which a sequence of observable\n","variables is generated by a sequence of internal hidden states.\n","\n","A set of hidden states S = {0,...,20} - 20 aminoacids + 1 noncoding state\n","\n","A set of possible observations O = {64 possible kmers}\n","\n","First state probabilities - probability that the kmer is the 1st kmer\n","\n","Transition probabilities - probability of moving from state Sn to state Sn+1​.\n","\n","Emission probabilities - probability that state Sn will emit observation Ok"],"metadata":{"id":"JXLSVsqDBRIR"}},{"cell_type":"markdown","source":["e. Wile multiplying many small probabilities, the number can become small and the computer treats it as zero. Taking the log turns multiplications into additions."],"metadata":{"id":"LRLGFdiJ8nIZ"}}],"metadata":{"colab":{"provenance":[{"file_id":"1Cz8yPuTgKMdEpFi16Ykkq3UQLkqQ6sXV","timestamp":1736542443215}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}